================================================================================
DEVELOPMENT OF AN INTELLIGENT SYSTEM FOR DIABETES CLASSIFICATION
USING MACHINE LEARNING: A COMPARATIVE ANALYSIS
================================================================================
Report Generated: October 18, 2025 at 02:23 AM
Student: UGOARU KINGSLEY NWACHUKWU (20201249402)
Department: Information Technology
Institution: Federal University of Technology, Owerri
Supervisor: Mrs Vivian Mbamala

================================================================================
EXECUTIVE SUMMARY
================================================================================

This project developed and compared three machine learning algorithms for
diabetes classification: Naïve Bayes, Support Vector Machine (SVM), and
Decision Tree. The system was trained and evaluated on the Pima Indians
Diabetes Database containing 768 patient records.

The Naive Bayes model achieved the best overall performance with an
accuracy of 70.13% and F1-Score of 0.5965, making it the most
suitable for diabetes classification in clinical settings.

================================================================================
SECTION 1: DATASET INFORMATION
================================================================================

Dataset Name: Pima Indians Diabetes Database
Source: UCI Machine Learning Repository
Total Records: 768 female patients
Age Range: 21 years and above
Features: 8 clinical measurements
Target Variable: Outcome (0=Non-Diabetic, 1=Diabetic)

Feature Description:
  1. Pregnancies: Number of times pregnant
  2. Glucose: Plasma glucose concentration (mg/dL)
  3. BloodPressure: Diastolic blood pressure (mm Hg)
  4. SkinThickness: Triceps skin fold thickness (mm)
  5. Insulin: 2-Hour serum insulin (mu U/ml)
  6. BMI: Body mass index (weight in kg/(height in m)^2)
  7. DiabetesPedigreeFunction: Diabetes pedigree function
  8. Age: Age in years

Class Distribution:
  Non-Diabetic (0): 500 patients (65.1%)
  Diabetic (1): 268 patients (34.9%)

================================================================================
SECTION 2: DATA PREPROCESSING METHODOLOGY
================================================================================

2.1 HANDLING MISSING VALUES
--------------------------------------------------------------------------------
Several features contained zero values that were medically impossible:
  • Glucose: 5 zero values (0.65%)
  • BloodPressure: 35 zero values (4.56%)
  • SkinThickness: 227 zero values (29.56%)
  • Insulin: 374 zero values (48.70%)
  • BMI: 11 zero values (1.43%)

Treatment:
  1. Zero values were replaced with NaN (Not a Number)
  2. Missing values were imputed using median values
  3. Median imputation was chosen for robustness against outliers

2.2 DATA SPLITTING
--------------------------------------------------------------------------------
  Training Set: 614 samples (80%)
  Testing Set: 154 samples (20%)
  Stratified split: Maintained class distribution in both sets
  Random State: 42 (for reproducibility)

2.3 FEATURE SCALING
--------------------------------------------------------------------------------
  Method: StandardScaler (Z-score normalization)
  Purpose: Standardize features to mean=0 and std=1
  Result: All features transformed to comparable scales
  This prevents features with larger ranges from dominating the models

================================================================================
SECTION 3: MACHINE LEARNING MODELS DEVELOPED
================================================================================

Three supervised learning algorithms were implemented and compared:

3.1 NAÏVE BAYES (GAUSSIAN)
--------------------------------------------------------------------------------
Algorithm Type: Probabilistic classifier
Assumption: Features are conditionally independent given the class
Mathematical Basis: Bayes' Theorem
Training Approach: No hyperparameter tuning required
Cross-Validation: 5-fold CV

Training Results:
  Mean CV Accuracy: 0.7590
  Training Time: 0.06 seconds

Advantages:
  • Fast training and prediction
  • Works well with small datasets
  • Probabilistic interpretation
  • Low computational requirements

3.2 SUPPORT VECTOR MACHINE (SVM)
--------------------------------------------------------------------------------
Algorithm Type: Margin-based classifier
Objective: Find optimal hyperplane that maximizes margin between classes
Training Approach: Grid Search with Cross-Validation

Hyperparameter Search Space:
  • C (Regularization): [0.1, 1, 10, 100]
  • Kernel: ['linear', 'rbf', 'poly']
  • Gamma: ['scale', 'auto', 0.001, 0.01]
  Total Combinations Tested: 48

Training Results:
  Best CV Accuracy: 0.7769
  Training Time: 10.17 seconds

Advantages:
  • Effective in high-dimensional spaces
  • Memory efficient (uses support vectors)
  • Versatile (different kernel functions)
  • Strong generalization capability

3.3 DECISION TREE
--------------------------------------------------------------------------------
Algorithm Type: Tree-based classifier
Method: Recursive binary splitting
Training Approach: Grid Search with Cross-Validation

Hyperparameter Search Space:
  • Max Depth: [3, 5, 7, 10, None]
  • Min Samples Split: [2, 5, 10, 20]
  • Min Samples Leaf: [1, 2, 4]
  • Criterion: ['gini', 'entropy']
  Total Combinations Tested: 160

Training Results:
  Best CV Accuracy: 0.7558
  Training Time: 1.97 seconds

Advantages:
  • Easy to understand and interpret
  • Requires little data preprocessing
  • Can handle non-linear relationships
  • Visual representation possible

================================================================================
SECTION 4: MODEL EVALUATION AND PERFORMANCE COMPARISON
================================================================================

4.1 EVALUATION METHODOLOGY
--------------------------------------------------------------------------------
All models were evaluated on an independent test set (154 samples) that was
not used during training. The following metrics were calculated:

Metrics Used:
  • Accuracy: Overall correctness of predictions
  • Precision: Proportion of positive predictions that are correct
  • Recall: Proportion of actual positives that are identified
  • F1-Score: Harmonic mean of precision and recall

4.2 COMPARATIVE PERFORMANCE RESULTS
--------------------------------------------------------------------------------

Model Performance Summary:
================================================================================
Model                Accuracy     Precision    Recall       F1-Score    
================================================================================
Naive Bayes          0.7013       0.5667       0.6296       0.5965      
SVM                  0.6948       0.5778       0.4815       0.5253      
Decision Tree        0.6883       0.6364       0.2593       0.3684      
================================================================================

4.3 DETAILED ANALYSIS BY MODEL
--------------------------------------------------------------------------------

NAIVE BAYES
--------------------------------------------------------------------------------
Accuracy: 70.13%
Precision: 0.5667
Recall: 0.6296
F1-Score: 0.5965

Confusion Matrix:
  True Negatives (TN):   74 (Correctly predicted Non-Diabetic)
  False Positives (FP):  26 (Incorrectly predicted Diabetic)
  False Negatives (FN):  20 (Missed Diabetic cases)
  True Positives (TP):   34 (Correctly predicted Diabetic)

Clinical Interpretation:
  • Detection Rate: 63.0% of diabetic patients identified
  • Missed Cases: 20 diabetic patients not detected
  • False Alarms: 26 healthy patients flagged

SVM
--------------------------------------------------------------------------------
Accuracy: 69.48%
Precision: 0.5778
Recall: 0.4815
F1-Score: 0.5253

Confusion Matrix:
  True Negatives (TN):   81 (Correctly predicted Non-Diabetic)
  False Positives (FP):  19 (Incorrectly predicted Diabetic)
  False Negatives (FN):  28 (Missed Diabetic cases)
  True Positives (TP):   26 (Correctly predicted Diabetic)

Clinical Interpretation:
  • Detection Rate: 48.1% of diabetic patients identified
  • Missed Cases: 28 diabetic patients not detected
  • False Alarms: 19 healthy patients flagged

DECISION TREE
--------------------------------------------------------------------------------
Accuracy: 68.83%
Precision: 0.6364
Recall: 0.2593
F1-Score: 0.3684

Confusion Matrix:
  True Negatives (TN):   92 (Correctly predicted Non-Diabetic)
  False Positives (FP):   8 (Incorrectly predicted Diabetic)
  False Negatives (FN):  40 (Missed Diabetic cases)
  True Positives (TP):   14 (Correctly predicted Diabetic)

Clinical Interpretation:
  • Detection Rate: 25.9% of diabetic patients identified
  • Missed Cases: 40 diabetic patients not detected
  • False Alarms: 8 healthy patients flagged

================================================================================
SECTION 5: BEST MODEL SELECTION AND JUSTIFICATION
================================================================================

Selected Model: Naive Bayes
--------------------------------------------------------------------------------

Performance Summary:
  Accuracy:  70.13%
  Precision: 0.5667
  Recall:    0.6296
  F1-Score:  0.5965

Selection Criteria:
The Naive Bayes was selected as the best model based on the F1-Score metric,
which provides the best balance between precision and recall. In medical
diagnosis applications, both false positives and false negatives have
significant consequences:

False Negatives (Missed Diabetic Cases): 20
  Risk: Patients remain undiagnosed and untreated, leading to potential
  complications such as kidney failure, vision loss, and cardiovascular issues.

False Positives (Incorrect Diabetic Diagnosis): 26
  Risk: Unnecessary anxiety, additional testing, and potential treatment
  side effects for healthy individuals.

The Naive Bayes achieved the optimal trade-off between these two types of
errors, making it the most suitable for clinical deployment.

================================================================================
SECTION 6: CONCLUSION
================================================================================

This comparative study successfully developed and evaluated three machine
learning algorithms for diabetes classification. Key findings include:

Key Achievements:
  ✓ Successfully preprocessed 768 patient records
  ✓ Trained and optimized three ML algorithms
  ✓ Achieved 70.13% accuracy with the best model
  ✓ Conducted comprehensive comparative analysis
  ✓ Generated detailed performance metrics and visualizations

Comparative Insights:
  1st Place: Naive Bayes (F1-Score: 0.5965)
  2nd Place: SVM (F1-Score: 0.5253)
  3rd Place: Decision Tree (F1-Score: 0.3684)

Clinical Relevance:
  The developed system demonstrates the potential of machine learning in
  supporting early diabetes detection. With proper validation and integration
  into healthcare workflows, such systems can:
    • Reduce diagnostic delays
    • Support healthcare workers in resource-limited settings
    • Enable large-scale screening programs
    • Improve patient outcomes through early intervention

================================================================================
SECTION 7: RECOMMENDATIONS
================================================================================

For Future Research:
  1. Collect and incorporate local Nigerian patient data for model retraining
  2. Explore ensemble methods combining multiple algorithms
  3. Investigate deep learning approaches for feature extraction
  4. Include temporal data (glucose monitoring over time)
  5. Conduct clinical validation studies with healthcare professionals

For Implementation:
  1. Develop user-friendly interface for healthcare workers
  2. Integrate with electronic health record systems
  3. Provide explainable predictions for clinical decision support
  4. Implement continuous model monitoring and updating
  5. Conduct pilot testing in selected healthcare facilities

For Healthcare Policy:
  1. Establish guidelines for AI-assisted diabetes screening
  2. Ensure data privacy and security compliance
  3. Train healthcare workers on ML system interpretation
  4. Develop quality assurance protocols
  5. Create regulatory framework for medical ML applications

================================================================================
SECTION 8: LIMITATIONS OF THE STUDY
================================================================================

1. Dataset Limitations:
   • Dataset based on Pima Indian population (may not generalize to Nigerians)
   • Limited sample size (768 records)
   • Class imbalance (65% non-diabetic, 35% diabetic)
   • Significant missing data in some features (especially Insulin)

2. Model Limitations:
   • Binary classification only (diabetic vs non-diabetic)
   • Does not distinguish between Type 1 and Type 2 diabetes
   • Static prediction (no temporal monitoring)
   • Limited to 8 clinical features

3. Validation Limitations:
   • No external validation on independent datasets
   • No clinical trial or real-world testing
   • No comparison with expert clinician diagnoses

4. Implementation Limitations:
   • Requires digital infrastructure
   • Dependent on data quality and completeness
   • May require periodic retraining

================================================================================
SECTION 9: REFERENCES
================================================================================

Dataset:
  Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S.
  (1988). Using the ADAP learning algorithm to forecast the onset of diabetes
  mellitus. Proceedings of the Symposium on Computer Applications and Medical
  Care, IEEE Computer Society Press, 261-265.

Libraries and Tools:
  • Scikit-learn: Pedregosa et al. (2011). Journal of Machine Learning Research
  • Pandas: McKinney (2010). Data Structures for Statistical Computing in Python
  • NumPy: Harris et al. (2020). Nature
  • Matplotlib: Hunter (2007). Computing in Science & Engineering

================================================================================
APPENDICES
================================================================================

Appendix A: Generated Visualizations
  • Confusion matrices for all models
  • Performance comparison charts
  • ROC curves
  • Performance dashboard

Appendix B: Model Files
  • Naive_Bayes.pkl
  • SVM.pkl
  • Decision_Tree.pkl
  • best_model.pkl
  • scaler.pkl

Appendix C: Data Files
  • X_train_scaled.csv
  • X_test_scaled.csv
  • y_train.csv
  • y_test.csv

================================================================================
END OF REPORT
================================================================================

Report generated on: October 18, 2025 at 02:23 AM
Total pages: Approximately 15-20 pages when formatted

For questions or clarifications, contact:
UGOARU KINGSLEY NWACHUKWU
Department of Information Technology
Federal University of Technology, Owerri
